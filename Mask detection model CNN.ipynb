{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80f1dee",
   "metadata": {},
   "source": [
    "# Mask detection with mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d6b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model ,Sequential \n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten, AveragePooling2D, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img , img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82cfaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4 # lirning rate \n",
    "EPOCHS = 20 # N. Ebochs \n",
    "BS = 32 # Bache size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730bae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'D:\\Me\\Future\\Ai courses\\Data\\masks' # path of my data \n",
    "CAEIGORIES = ['with_mask','without_mask'] # items im my path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27c1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DR\\anaconda3\\lib\\site-packages\\PIL\\Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# for loop to add images in data and add (with_mask or without_mask ) in labels\n",
    "\n",
    "for category in CAEIGORIES:\n",
    "    path = os.path.join(DIRECTORY,category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path,img)\n",
    "        image = load_img(img_path,target_size = (224,224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603d67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer() # to convert (with_mask or without_mask ) to 0,1\n",
    "\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e99554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning data and add X , Y\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size = 0.20, random_state = 42, stratify = labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1695c11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for data augmentation\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2ddb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# create a new model by MobileNetV2 and ignore output   \n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# create my spicial output by cnn\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb40d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31cb2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DR\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "# optimizer details     \n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cab966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "95/95 [==============================] - 71s 717ms/step - loss: 0.4097 - accuracy: 0.8573 - val_loss: 0.1522 - val_accuracy: 0.9817\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 64s 670ms/step - loss: 0.1492 - accuracy: 0.9651 - val_loss: 0.0753 - val_accuracy: 0.9935\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 61s 642ms/step - loss: 0.0983 - accuracy: 0.9759 - val_loss: 0.0553 - val_accuracy: 0.9922\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 61s 639ms/step - loss: 0.0823 - accuracy: 0.9769 - val_loss: 0.0501 - val_accuracy: 0.9909\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 0.0650 - accuracy: 0.9829 - val_loss: 0.0416 - val_accuracy: 0.9922\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 0.0364 - val_accuracy: 0.9935\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 61s 639ms/step - loss: 0.0506 - accuracy: 0.9865 - val_loss: 0.0342 - val_accuracy: 0.9935\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 62s 648ms/step - loss: 0.0451 - accuracy: 0.9865 - val_loss: 0.0324 - val_accuracy: 0.9935\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 61s 640ms/step - loss: 0.0498 - accuracy: 0.9845 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 0.0311 - val_accuracy: 0.9935\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 63s 661ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 0.0307 - val_accuracy: 0.9935\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0347 - val_accuracy: 0.9896\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 61s 639ms/step - loss: 0.0402 - accuracy: 0.9888 - val_loss: 0.0291 - val_accuracy: 0.9922\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0278 - val_accuracy: 0.9935\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 0.0366 - accuracy: 0.9901 - val_loss: 0.0275 - val_accuracy: 0.9935\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 61s 643ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.0305 - val_accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 60s 632ms/step - loss: 0.0294 - accuracy: 0.9901 - val_loss: 0.0267 - val_accuracy: 0.9935\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.0273 - val_accuracy: 0.9935\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 60s 636ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.0277 - val_accuracy: 0.9935\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.0315 - val_accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(\n",
    "aug.flow(X_train, y_train, batch_size=BS),\n",
    "steps_per_epoch=len(X_train) // BS,\n",
    "validation_data=(X_test, y_test),\n",
    "validation_steps=len(X_test) // BS,\n",
    "epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eb573cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 12s 480ms/step\n"
     ]
    }
   ],
   "source": [
    "# pridecting X_test\n",
    "predIdxs = model.predict(X_test, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e1376db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ace2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e0630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
